# üì¶ Livrables - Projet d‚Äôanalyse de donn√©es pand√©miques

## 1. Mod√®le de donn√©es UML

- UML : `csv_to_postgres/schema BDD.svg`
- MCD : `csv_to_postgres/MCD.svg`
- MLD : `csv_to_postgres/MLD.svg`
- MPD : `csv_to_postgres/MPD.svg`

Repr√©sentation compl√®te du sch√©ma relationnel de la base de donn√©es utilis√©e pour centraliser les diff√©rentes sources de donn√©es.

---

## 2. Base de donn√©es relationnelle & script de cr√©ation

Afin de cr√©er la base de donn√©es PostgreSQL, veuillez t√©l√©charger la suite logicielle PostgreSQL :

üëâ [PostgreSQL - EnterpriseDB](https://www.enterprisedb.com/downloads/postgres-postgresql-downloads)

### √âtapes de mise en place :

1. Installer PostgreSQL et pgAdmin.
2. Lancer pgAdmin et cr√©er un **nouveau serveur**.
    - Exemple :
        - Nom du serveur : `localhost`
        - Hostname : `localhost`
        - Username : `postgres` ou celui d√©fini √† l'installation de PostgreSQL
        - Mot de passe : celui d√©fini √† l‚Äôinstallation de PostgreSQL
3. Cr√©er une **nouvelle base de donn√©es** nomm√©e `MSPR`.

---

## 3. Mise en fonctionnement de l‚ÄôApollo Server

**GraphQL** permet des requ√™tes souples et cibl√©es sur les donn√©es nettoy√©es.

### Configuration des variables d‚Äôenvironnement

Avant de lancer le serveur, configurez les variables d‚Äôenvironnement n√©cessaires √† la connexion √† la base de donn√©es PostgreSQL.

1. Copiez le fichier `.env.example` en `.env` dans le dossier `backend` :

```bash
cp .env.example .env
```

2. Ouvrez le fichier `.env` et remplacez les valeurs par d√©faut par vos informations r√©elles, notamment le **mot de passe** et le **nom d‚Äôutilisateur** PostgreSQL si vous les avez modifi√©s lors de l‚Äôinstallation.

Exemple de section √† modifier dans `.env`¬†:

```
DATABASE_URL="postgresql://<utilisateur>:<mot_de_passe>@localhost:5432/MSPR?schema=public"
```

Assurez-vous que ces informations correspondent √† celles de votre instance PostgreSQL.

### Installation des d√©pendances

Depuis le dossier `backend` :

```bash
npm install
```

### D√©ploiement des migrations Prisma

```bash
npx prisma migrate deploy
```

### G√©n√©ration du client Prisma

```bash
npx prisma generate
```

### Lancement du serveur

```bash
npm run start
```

---

## 4. Importation des donn√©es dans la base

Depuis le dossier `csv_to_postgres` :

1. Cr√©er un environnement virtuel :

```bash
py -m venv venv
```

2. Installer les d√©pendances :

```bash
pip install -r requirements.txt
```

3. Lancer le script d‚Äôimportation :

```bash
py migration-script.py
```

---

## 5. Code ETL

üìÅ Notebook Jupyter : `etl/data_cleaning.ipynb`

Contient l‚Äôensemble du processus de pr√©paration, nettoyage et fusion des donn√©es brutes.

---

## 6. Documentation API (OpenAPI Spec)

[√Ä compl√©ter]

---

## 7. Tableau de bord interactif

Outil utilis√© : Power BI

- Exploration des donn√©es historiques des pand√©mies
- Exportation des visualisations
- Application de filtres pour faciliter la lecture

---

## 8. Documentation d√©taill√©e : collecte et nettoyage des donn√©es

R√©sum√© du notebook :

> La fusion des jeux de donn√©es repose sur une normalisation pr√©alable de chaque source pour garantir une homog√©n√©it√© avant la fusion. Cela permet de minimiser les incoh√©rences et de limiter le nettoyage post-fusion.

### √âtapes cl√©s :

1. Suppression des colonnes inutiles et harmonisation des noms
2. Gestion des valeurs manquantes (suppression ou imputation)
3. Formatage des types (dates, float, etc.)
4. V√©rification de la coh√©rence intercolonnes
5. Suppression des doublons intradataset
6. Fusion des datasets
7. D√©tection de doublons interdatasets apr√®s fusion
8. Feature Engineering :
    - Taux de croissance des cas
    - Taux de mortalit√©
    - % de population touch√©e
    - Saisonnalit√©
    - Moyennes mondiales de r√©f√©rence

---

## 9. Benchmark des solutions techniques

### **ETL & Pr√©paration**

- `Pandas` ‚Üí R√©f√©rence en traitement CSV
- `Jupyter Notebook` ‚Üí It√©ration rapide et visualisation instantan√©e

---

### **Stockage des donn√©es**

- **PostgreSQL (choix)** ‚Üí Choix principal, robuste & int√©gr√©
- **Alternatives** :
    - MySQL / MariaDB ‚Üí Bonne alternative si PostgreSQL n‚Äôest pas requis
    - DuckDB ‚Üí Id√©al pour requ√™tes analytiques sur des fichiers locaux
    - ClickHouse ‚Üí Tr√®s rapide pour de la data analytique
    - BigQuery ‚Üí Si besoin de requ√™ter des datasets massifs sur le cloud
- **ORMs** :
    - Prisma (Node.js) ‚Üí ORM typ√©, moderne et multi-SGBD
    - SQLAlchemy (Python) ‚Üí Int√©gr√© pour l‚Äôexport depuis le notebook

---

### **API & CRUD**

- **GraphQL (choix)** ‚Üí Requ√™tage cibl√© et structur√©
- **REST (FastAPI, Express.js)** ‚Üí Standard mais moins souple
- **Librairies** : Apollo Server (Node.js)

---

### **Visualisation des donn√©es**

- **Power BI (choix)** ‚Üí Recommand√© pour filtres, export, et dashboards clairs
- **Matplotlib**, **Seaborn** ‚Üí Explorations initiales
- **Plotly**, **Bokeh** ‚Üí Graphiques interactifs
- **Apache Superset**, **Metabase** ‚Üí Solutions open-source

---

## 10. Diagramme de Gantt
